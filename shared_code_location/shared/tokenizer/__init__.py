def simple_tokenizer(text):
    """Tokenize text by splitting on whitespace.
    Args:
        text (str): The input text to tokenize.
    Returns:
        list[str]: List of tokens.
    """
    return text.split()
